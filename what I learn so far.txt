Section 3: TensorFlow.js Core Concepts
	19. Memory Mnagement in TensorFlow.js
		- Tensors stored in WebGL, operations happen in WebGL
		- JS has garbage collection but WebGL backend has no garbage collection
		- not strictly necessary without WebGL backend
 			+ "tf.tidy(functionName)" will free up memory after function executed and result ouput to console
			+ "tf.memory()" check memory usage

Section 4: Data Preparation with TensorFlow.js
	23. Linear Regression
		- search for free dataset on "https://www.kaggle.com/datasets"
	24. Reading data from CSV
		- need to load the CSV file through http webserver
		- "npm install http-server -g" to set up a simple http server
	28. Splitting into Training and Testing data
		- shuffle before splitting into sets
		- avoids patterns in order of data
		-"tf.util.shuffle(arrayName)" to shuffle the whole array
		- make sure the array length is even when splitting, otherwise may get error

Section 5 : Defining a model
	35. Compile a model
		- with normalized data, RMSE less meaningful, so prefer MSE

Section 6 : Training and Testing 
	41. visualize loss with tfjs-vis
		- may consider using "adam" as optimizer since it is a modern one that does not require to set a learning rate

Section 7:
	- when browser stuck with old html version => hard reload the tab by Ctrl + F5, on laptop is Ctrl + fn + F5

Section 8:
	59. Binary Classification model
		- use "sigmoid" for activation function when doing binary classification
		- use "adam" for optimizer so that dont have to deal with scg or learning rate
		- use "binaryCrossentropy" for loss function when "model.compile"
	- only have a single output where either : 1 or 0

Section 9: Multi-class classification
	60. Introduction
		- for each class, a decimal value between 0 and 1, can be considerd likelihood. 0.8 = 80% likelihood of sitting in class
	67. Multi-class classification model
		- on the last layer, set number of "units" to number of class and "activation" function to softmax
			+ softmax normalizes ouput to sum to 1.0
			+ sigmoid gives node output between 0 and 1.0
		- change "loss" function in "model.compile" to "categoricalCrossentropy"
	68. Visualising multi-class predictions
		- in the headmap
			+ full domain: show heat map in a scale between 0.0 and 1.0, work well for fully trained model
			+ local: show heat map that show the model in training
		- in case the heatmap and scatterplot does not match up, in term of seperating lines => set "equalizeClassSizes" to true (function plotClasses)
			
	